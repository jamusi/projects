# Pixel Glasses

## Introduction

See the world through the power of machine learning. And a red headband.

## Description

Artificial intelligence lets us do things today that were unimaginable in the past. One of those things is letting people who would otherwise not be able to see the world due to blindness, experience things around them through image recognition and speech synthesis.

Pixel Glasses let you do just that. The headset uses Microsoft's Machine Learning-based image recognition algorithms to identify objects in the view of a phone, placed in a headset of the user. The user is then told what the camera is seeing, via their headphones.

Pixel Glasses is made of three parts:

* A Javascript-based server application, that handles requests and processes the responses from Image Processing, Computer Vision, Natural Language, Translation and Speech Synthesis APIs.
* A iOS swift-based native application, that runs on iPhones and iPads.
* A React-native based interface, for every other device.

## Team

* David Francisco (https://pixels.camp/dmfrancisco)
* Fred Oliveira (https://pixels.camp/fredoliveira)
* Jo√£o Oliveira (https://pixels.camp/gunzstyles)
* Pedro Gaspar (https://pixels.camp/pgaspar)

## Code repository

Soon to be released.

## URL

Not available yet.

## Other information

Not applicable.
